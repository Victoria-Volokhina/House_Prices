{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicates\nidsUnique = len(set(train.Id))\nidsTotal = train.shape[0]\nidsDupli = idsTotal - idsUnique\nprint(\"There are \" + str(idsDupli) + \" duplicate IDs for \" + str(idsTotal) + \" total entries\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ID = test['Id']\n\n#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#corr = train.corr()\n\n# Коррелиция признаков\n#f,ax = plt.subplots(figsize=(18, 18))\n#sns.heatmap(corr, annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n#plt.show()\n\n# Поиск 10ти самых влиятельных признаков\n#corr.sort_values([\"SalePrice\"], ascending = False, inplace = True)\n#print(corr.SalePrice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (24, 12))\n\ncorr = train.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(corr, mask = mask, cmap = 'PiYG', annot = True, fmt=\".2f\")\n\nplt.yticks(rotation=0) \nplt.xticks(rotation=90)\nplt.title('Correlation Matrix for Train Data', fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Корреляция признаков. Скаттер с точками\n\n#sns.pairplot(train[['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', \n#                    'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем выбросы\n\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log transformation\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Соединим train and test\nntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\ntrain.drop(['SalePrice'], axis=1, inplace=True)\nall_data = pd.concat((train, test)).reset_index(drop=True)\nprint(\"all_data size is : {}\".format(all_data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data\ntotal = all_data.isnull().sum().sort_values(ascending=False)\npercent = (all_data.isnull().sum()/all_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['Exterior2nd'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing missing values\n\nall_data['PoolQC'] = all_data['PoolQC'].fillna('NA')\nall_data['MiscFeature'] = all_data['MiscFeature'].fillna('NA')\nall_data['Alley'] = all_data['Alley'].fillna('NA')\nall_data['Fence'] = all_data['Fence'].fillna('NA')\nall_data['FireplaceQu'] = all_data['FireplaceQu'].fillna('NA')\nall_data['GarageType'] = all_data['GarageType'].fillna('NA')\nall_data['GarageCond'] = all_data['GarageCond'].fillna('NA')\nall_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna('NA')\nall_data['GarageFinish'] = all_data['GarageFinish'].fillna('NA')\nall_data['GarageQual'] = all_data['GarageQual'].fillna('NA')\nall_data['BsmtExposure'] = all_data['BsmtExposure'].fillna('NA')\nall_data['BsmtFinType2'] = all_data['BsmtFinType2'].fillna('NA')\nall_data['BsmtFinType1'] = all_data['BsmtFinType1'].fillna('NA')\nall_data['BsmtCond'] = all_data['BsmtCond'].fillna('NA')\nall_data['MasVnrType'] = all_data['MasVnrType'].fillna('None')\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data.Electrical.value_counts().idxmax())\nall_data['BsmtQual'] = all_data['BsmtQual'].fillna('NA')\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data.MSZoning.value_counts().idxmax())\nall_data['Utilities'] = all_data['Utilities'].fillna(all_data.Utilities.value_counts().idxmax())\nall_data['Functional'] = all_data['Functional'].fillna(all_data.Functional.value_counts().idxmax())\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna('TA')\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna('Other')\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data.SaleType.value_counts().idxmax())\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data.Exterior1st.value_counts().idxmax())\nall_data['MasVnrArea'] = all_data['MasVnrArea'].fillna(0)\nall_data['LotFrontage'] = all_data['LotFrontage'].fillna(0)\nall_data['BsmtFullBath'] = all_data['BsmtFullBath'].fillna(0)\nall_data['BsmtHalfBath'] = all_data['BsmtHalfBath'].fillna(0)\nall_data['BsmtUnfSF'] = all_data['BsmtUnfSF'].fillna(0)\nall_data['TotalBsmtSF'] = all_data['TotalBsmtSF'].fillna(0)\nall_data['BsmtFinSF2'] = all_data['BsmtFinSF2'].fillna(0)\nall_data['BsmtFinSF1'] = all_data['BsmtFinSF1'].fillna(0)\nall_data['GarageCars'] = all_data['GarageCars'].fillna(0)\nall_data['GarageArea'] = all_data['GarageArea'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].astype('object')\n\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype('object')\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YearBuilt'] = all_data['YearBuilt'].astype('object')\nall_data['YearRemodAdd'] = all_data['YearRemodAdd'].astype('object')\nall_data['YrSold'] = all_data['YrSold'].astype('object')\nall_data['MoSold'] = all_data['MoSold'].astype('object')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удалим сильно связанные колонки\nall_data.drop(['1stFlrSF'], axis=1, inplace=True)\nall_data.drop(['TotRmsAbvGrd'], axis=1, inplace=True)\nall_data.drop(['GarageYrBlt'], axis=1, inplace=True)\nall_data.drop(['GarageArea'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавим колонку\nall_data['tot_sf'] = all_data['TotalBsmtSF'] + all_data['GrLivArea']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразование признаков с отклонениями\nnumerical_features = all_data.select_dtypes(exclude = [\"object\"]).columns\nskewness = all_data[numerical_features].skew()\nskewed_features = skewness[abs(skewness) > 0.75].index\nall_data[skewed_features] = np.log1p(all_data[skewed_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразование категориальных признаков в таблицу 0 и 1 созданием фиктивных колонок\n\nall_data = pd.get_dummies(all_data)\nprint(all_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = all_data[:ntrain]\nX_test = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Modeling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Нормализация признаков (одинаковый масштаб)\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\nalphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() for alpha in alphas]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_ridge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation - Just Do It\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"rmse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" min(cv_ridge)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005], cv=5).fit(X_train, y_train)\nrmse_cv(model_lasso).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lasso = LassoCV(alphas = [0.001], cv=5).fit(X_train, y_train)\nrmse_cv(model_lasso).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lasso_preds = np.expm1(model_lasso.predict(X_test))\nsolution = pd.DataFrame({\"id\":test_ID, \"SalePrice\":lasso_preds})\n#solution.to_csv(\"lasso.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\nclf = GradientBoostingRegressor(learning_rate=0.1, n_estimators=500, random_state=241)\n#rmse_cv(clf).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural net"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\nclf = MLPRegressor(hidden_layer_sizes=(30, 20, 15), solver='lbfgs', alpha=1e-5, random_state=1)\n#rmse_cv(clf).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n# Misc\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup cross validation folds\nkf = KFold(n_splits=12, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define error metrics\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model, X_train=X_train):\n    rmse = np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n    return (rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup models\n\n# Light Gradient Boosting Regressor\nlightgbm = LGBMRegressor(objective='regression', \n                       num_leaves=6,\n                       learning_rate=0.01, \n                       n_estimators=4000,\n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.2,\n                       feature_fraction_seed=8,\n                       min_sum_hessian_in_leaf = 11,\n                       verbose=-1,\n                       random_state=42)\n\n# XGBoost Regressor\nxgboost = XGBRegressor(learning_rate=0.01,\n                       n_estimators=6000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:linear',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\n# Ridge Regressor\nridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))\n\n# Support Vector Regressor\nsvr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n\n# Gradient Boosting Regressor\ngbr = GradientBoostingRegressor(n_estimators=6000,\n                                learning_rate=0.01,\n                                max_depth=4,\n                                max_features='sqrt',\n                                min_samples_leaf=15,\n                                min_samples_split=10,\n                                loss='huber',\n                                random_state=42)  \n\n# Random Forest Regressor\nrf = RandomForestRegressor(n_estimators=1200,\n                          max_depth=15,\n                          min_samples_split=5,\n                          min_samples_leaf=5,\n                          max_features=None,\n                          oob_score=True,\n                          random_state=42)\n\n# Stack up all the models above, optimized using xgboost\nstack_gen = StackingCVRegressor(regressors=(xgboost, lightgbm, svr, ridge, gbr, rf),\n                                meta_regressor=xgboost,\n                                use_features_in_secondary=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get cross validation scores for each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = {}\n\nscore = cv_rmse(lightgbm)\nprint(\"lightgbm: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['lgb'] = (score.mean(), score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cv_rmse(xgboost)\nprint(\"xgboost: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['xgb'] = (score.mean(), score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cv_rmse(svr)\nprint(\"SVR: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['svr'] = (score.mean(), score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cv_rmse(ridge)\nprint(\"ridge: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['ridge'] = (score.mean(), score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cv_rmse(rf)\nprint(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['rf'] = (score.mean(), score.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cv_rmse(gbr)\nprint(\"gbr: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['gbr'] = (score.mean(), score.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the models"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('stack_gen')\nstack_gen_model = stack_gen.fit(np.array(X_train), np.array(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('lightgbm')\nlgb_model_full_data = lightgbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('xgboost')\nxgb_model_full_data = xgboost.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Svr')\nsvr_model_full_data = svr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Ridge')\nridge_model_full_data = ridge.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RandomForest')\nrf_model_full_data = rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('GradientBoosting')\ngbr_model_full_data = gbr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Blend models and get predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Blend models in order to make the final predictions more robust to overfitting\ndef blended_predictions(X):\n    return ((0.1 * ridge_model_full_data.predict(X)) + \\\n            (0.2 * svr_model_full_data.predict(X)) + \\\n            (0.1 * gbr_model_full_data.predict(X)) + \\\n            (0.1 * xgb_model_full_data.predict(X)) + \\\n            (0.1 * lgb_model_full_data.predict(X)) + \\\n            (0.05 * rf_model_full_data.predict(X)) + \\\n            (0.35 * stack_gen_model.predict(np.array(X))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get final precitions from the blended model\nblended_score = rmsle(y_train, blended_predictions(X_train))\nscores['blended'] = (blended_score, 0)\nprint('RMSLE score on train data:')\nprint(blended_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_preds = np.floor(np.expm1(blended_predictions(X_test)))\nsolution = pd.DataFrame({\"id\":test_ID, \"SalePrice\":ensemble_preds})\nsolution.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}